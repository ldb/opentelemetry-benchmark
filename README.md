# opentelemetry-benchmark
A benchmarking tool for the [OpenTelemetry Collector](https://github.com/open-telemetry/opentelemetry-collector).

## About

This project contains all the code necessary to perform sophisticated maximum throughput benchmarks of the [OpenTelemetry Collector](https://github.com/open-telemetry/opentelemetry-collector).

Some features:
- Automatic provisioning of benchmarking infrastructure in Google Cloud using Terraform
- Ability to run pre-configured plans that describe the benchmark itself
- Easy to use CLI tool called `benchctl` to control and monitor the status of the benchmark
- Includes Prometheus based monitoring of all components, namely the collector, the benchmarking daemon and Prometheus itself
- Local Grafana Dashboard to easily monitor the components without having to analyze the log files

## Installation

The whole installation can be performed using the local *Makefile*. Run `make help` to get an overview of all the commands:

```shell
help                 Lists the available commands.
all                  Compiles binaries, provisions all infrastructure and starts Grafana Dashbaord.
compile              Compiles the binaries.
provision            Provisions all infrastructure in Google Cloud
dashboard            Deploy a local Grafana instance for easier monitoring
local                Spins up a local development environment.
clean                Remove build artifacts.
```

### Quickstart

The fastest way to run this project requires only two steps:
1. Make sure you have all dependencies installed. See *# Prerequisites* for the full list.
2. Run `make all`. This will automatically compile the code, provision the infrastructure and create a local Grafana Dashboard.  
For more information on these steps check out *# Compilation* and *# Provisioning*.

### Prerequisites

In order to make this tool as easy to use as possible, we tried minimizing external dependencies as much as possible.
However, a few things are still required. Namely:

- `terraform` (version 1.0 or higher) for bringing up the testing infrastructure in Google Cloud
- `gcloud`, the Google Cloud CLI to authenticate to Google Cloud
- `go` (version 1.17 or higher) for compiling the code.
- `docker` and `docker-compose` for a Grafana Dashbaord and local development. 

### Compilation

To compile you need to have the Go Programming Language environment installed. See [here](https://go.dev/doc/install) for installation instructions.

After that, simply run 
```shell
make compile
```

This will compile three binaries in the `./bin` directory: 
- `benchd`, which is the actual benchmarking daemon running in Google Cloud and is crosscompiled for linux/amd64
- `benchctl`, a command line tool to control one or more `benchd` instances at once
- `promdl`, a small tool that downloads the values of some predefined queries from the monitoring instance and saves the results as CSV files

### Provisioning

To provision the infrastructure simply run 
```shell
make provision
```

This runs Terraform and creates two files: `benchctl.config` and `privatekey.pem`.

**`benchctl.config`** contains a list of node names and their public IP addresses. 
This file is read by `benchctl`, the benchmarking controller.

**`privatekey.pem`** is a private SSH key for the `benchmark` user that can be used to SSH into the instances.
This should rarely be necessary, as the process is fully automated, but you never know.
To use it, use:
```shell
ssh -i privatekey.pem benchmark@{INSTANCE_IP}
```

Note that Terraform a simple firewall rule that grants networking access to all instances from the public IP of the current machine.
If you are using a VPN, or are in an environment that regularly rotates its public IP address, you may have trouble accessing the instances.

## Usage

All interactions with the Benchmarking Daemon `benchd` can be made over a simple HTTP based protocol. For convenience,
`benchctl` implements an easy to use client to communicate with `benchd`

### Overview
After compiling `benchctl` (see *# Compilation*), running it without any arguments will give you the following output: 
```shell
  -config string
        config file generated by terraform (default "benchctl.config")
  -plan string
        benchmarking plan to execute

```

`benchctl` requires two input files:
- A *config file*: This is creatd automatically by Terraform during Provisioning of the infrastructure. 
By default its called `benchctl.config`. It contains a list of IP addresses of the created instances.
- A *plan file*: This file contains a Benchmarking Plan, which is a definition of the different parameters for the benchmarking daemon.
A list of plan files can be found in `./plans`. **Important**: *Make sure to provision the Collector with the corresponding configuration before running a plan.
By default, it is provisioned with the `basic-1` configuration*

### Benchmark plans

Each Benchmark is described in a *plan file* that can be found under `./plans`. 
Note that a plan should only be run if the matching OpenTelemetry config (check the prefix) has been deployed.
To apply a different configuration, provide the respectie configuration name to the `sut_config_file` Terraform variable in `terraform/variables.tf`.

### promdl

`promdl` is a small tool that can be used to download relevant system and machine metrics from the instances for the time of a benchmark.  
It takes the following arguments:
```shell
  -end duration
        how much time to go back to end fetching fetch results from (default 30m0s)
  -host string
        Prometheus host URL
  -start duration
        how much time to go back to start fetching fetch results from (default 1h0m0s)
```
It downloads the results of a set of predefined queries between the timestamps of `[now-start, now-end]`.
Note that the granularity of results may vary, based on the size of the timeframe. For best comparability we recommend all benchmarks to have roughly the same duration.

## Study Design

We design the study around four basic categories of plans: 

- **basic** plans are meant to benchmark the raw performance of the OpenTelemetry collector without any features enabled. 
The workload is very synthetic and the plans are mostly differentiated by the scale of workers and the number of spans per trace and their depth.  
It is well suited for making an initial assessment on the infrastructure (e.g verify filedescriptor limits are high enough).
- **realistic** plans are meant to model more realistic workloads with fewer but longer spans that contain attributes.
- **mutate** plans are made for benchmarking a specific application scenario of the collector: Filtering out a specific "risky" attribute in incoming spans.
- **sampled** plans, similar to *filtered* ones model the behaviour of probabilistic sampling. In this scenario, a portion of all sent traces is expected to be sampled, the rest timing out on receiving.

The former two models are to answer the question of sensible deployment practices for an expected workload. They are of mere exploratorive nature.  
The latter two models iterate on these results and try to answer the question on how different features used in the collector affect its performance.  
We expect the mutating benchmark plans to perform worse (as additionatl computations and mutations take place), while the sampled workloads should perform better in sending (more sent traces), and similarly or slightly worse in receiving (some traces are sampled, so receiving will time out).

## Analysis

For our analysis we want to look at several qualities:
- Maximum throughput without causing any errors during sending or receiving (the sample plans are a special case here, more blow).
- Sustained maximum throuphut; based on the previous results we configure the benchmark to run at maximum throttle for 30 minutes
      - Here we are especially interested in the following metrics:
            - CPU and Memory usage of the collector during this time. Is it stable?
            - Roundtrip time latency (in 50th, 90th, 95th, 99th percentile)
            - How may traces is benchd emitting? How many spans is the collector accepting?
- How does the usage of processors such as mutations or sampling change these metrics?

Figures to make:
- For -50 plans:
      - number of clients, moving average of send rate of traces and accepted spans
      - sending rate, moving average of send latency in different percentiles
      - sending rate, moving average of receive latency in percentiles
- For -sustain plans:
      - one plot with all plans sending rates to compare throuhput
      - sending rate, moving average of receive latency in percentiles
